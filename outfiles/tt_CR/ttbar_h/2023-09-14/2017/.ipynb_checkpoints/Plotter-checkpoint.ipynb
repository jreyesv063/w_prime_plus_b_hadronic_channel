{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c95354-5d1e-4cf5-a6f3-015d9d82048a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import hist\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import pickle\n",
    "import argparse\n",
    "from coffea import processor\n",
    "import numpy as np\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "from hist.intervals import clopper_pearson_interval\n",
    "import pandas as pd\n",
    "\n",
    "np.seterr(divide=\"ignore\", invalid=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c6d355-a67e-49da-b3ae-a5645f15809f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66290467-eb0c-434f-8e69-b6c40fb3b0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load cross sections\n",
    "main_path = Path.cwd().parent.parent\n",
    "with open(f\"../../../../../wprime_plus_b/data/DAS_xsec.json\", \"r\") as f:\n",
    "    xsecs = json.load(f)\n",
    "# define luminosity\n",
    "lumi = 41477.877399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d897201-0f77-450b-983d-3237fbaeb27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_output(fname):\n",
    "    with open(fname, \"rb\") as f:\n",
    "        h = pickle.load(f)\n",
    "    return h\n",
    "\n",
    "def open_metadata(fname):\n",
    "    with open(fname, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b17a7535-4e3e-4855-a49d-8a6551acb3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_outputs(metadata=False) -> dict:\n",
    "    \"\"\"group output .pkl files by sample\"\"\"\n",
    "    if metadata:\n",
    "        extension = \".json\"\n",
    "        output_files = glob.glob(f\"/metadata/*{extension}\", recursive=True)\n",
    "    else:\n",
    "        extension = \".pkl\"\n",
    "        output_files = glob.glob(f\"/*{extension}\", recursive=True)\n",
    "        \n",
    "    grouped_outputs = {}\n",
    "    for output_file in output_files:\n",
    "        # get output file names\n",
    "        sample_name = output_file.replace(\"_metadata\", \"\").split(\"/\")[-1].split(extension)[0]\n",
    "        if sample_name.rsplit(\"_\")[-1].isdigit():\n",
    "            sample_name = \"_\".join(sample_name.rsplit(\"_\")[:-1])\n",
    "        # append file names to grouped_outputs\n",
    "        if sample_name in grouped_outputs:\n",
    "            grouped_outputs[sample_name].append(output_file)\n",
    "        else:\n",
    "            grouped_outputs[sample_name] = [output_file]\n",
    "    return grouped_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3f0fa95-5a20-44c5-bd1b-fcf29e930581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_outputs_metadata = group_outputs(metadata=True)\n",
    "\n",
    "grouped_metadata = {}\n",
    "first_accumulated_metadata = {}\n",
    "for sample in grouped_outputs_metadata:\n",
    "    grouped_metadata[sample] = []\n",
    "    for fname in grouped_outputs_metadata[sample]:\n",
    "        output = open_metadata(fname)\n",
    "        meta = {}\n",
    "        if sample not in [\"SingleElectron\", \"SingleMuon\"]:\n",
    "            sumw = output[\"sumw\"]\n",
    "            meta[\"sumw\"] = sumw\n",
    "        meta[\"events_before\"] = output[\"events_before\"]\n",
    "        meta[\"events_after\"] = output[\"events_after\"]\n",
    "        grouped_metadata[sample].append(meta)\n",
    "    first_accumulated_metadata[sample] = processor.accumulate(grouped_metadata[sample]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecf0012c-1e8b-461f-84e5-98f210d14475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Data/bkg'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 71\u001b[0m\n\u001b[1;32m     64\u001b[0m bkg_err \u001b[38;5;241m=\u001b[39m report_df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal bkg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#report_df.loc[\"Data/bkg\", \"events\"] = data / bkg\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#report_df.loc[\"Data/bkg\", \"error\"] = np.sqrt(\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#    (1 / bkg) ** 2 * data_err**2 + (data / bkg**2) ** 2 * bkg_err**2\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# sort processes by percentage\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m report_df \u001b[38;5;241m=\u001b[39m \u001b[43mreport_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmcs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTotal bkg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData/bkg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     72\u001b[0m report_df \u001b[38;5;241m=\u001b[39m report_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpercentage\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# drop process with no events\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1239\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1430\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1432\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Data/bkg'] not in index\""
     ]
    }
   ],
   "source": [
    "mcs = [\"DYJetsToLL\", \"WJetsToLNu\", \"VV\", \"VVV\", \"tt\", \"SingleTop\"]\n",
    "events = {sample: 0 for sample in mcs}\n",
    "events.update({\"Data\": 0})\n",
    "errors = events.copy()\n",
    "\n",
    "for sample in first_accumulated_metadata:\n",
    "    if (\"SingleElectron\" in sample) or (\"SingleMuon\" in sample) or (\"SingleTau\" in sample):\n",
    "        events[\"Data\"] += first_accumulated_metadata[sample][\"events_after\"]\n",
    "        errors[\"Data\"] += np.sqrt(events[\"Data\"])\n",
    "        continue\n",
    "    # get number of events before selection\n",
    "    nevents = first_accumulated_metadata[sample][\"events_before\"]\n",
    "\n",
    "    # get number of events after selection\n",
    "    n_mc = first_accumulated_metadata[sample][\"events_after\"]\n",
    "\n",
    "    # get expected number of events\n",
    "    weight = (xsecs[sample] * lumi) / nevents\n",
    "    n_phys = weight * n_mc\n",
    "\n",
    "    # get statistical error\n",
    "    error = weight * np.sqrt(n_mc)\n",
    "\n",
    "    if \"DYJetsToLL\" in sample:\n",
    "        events[\"DYJetsToLL\"] += n_phys\n",
    "        errors[\"DYJetsToLL\"] += error\n",
    "    elif \"WJetsToLNu\" in sample:\n",
    "        events[\"WJetsToLNu\"] += n_phys\n",
    "        errors[\"WJetsToLNu\"] += error\n",
    "    elif (sample == \"WW\") or (sample == \"WZ\") or (sample == \"ZZ\"):\n",
    "        events[\"VV\"] += n_phys\n",
    "        errors[\"VV\"] += error\n",
    "    elif \"TTT\" in sample:\n",
    "        events[\"tt\"] += n_phys\n",
    "        errors[\"tt\"] += error\n",
    "    elif \"ST\" in sample:\n",
    "        events[\"SingleTop\"] += n_phys\n",
    "        errors[\"SingleTop\"] += error\n",
    "\n",
    "# add number of expected events and errors to report\n",
    "report_df = pd.DataFrame(columns=[\"events\", \"error\", \"percentage\"])\n",
    "for sample in events:\n",
    "    report_df.loc[sample, \"events\"] = events[sample]\n",
    "    report_df.loc[sample, \"error\"] = errors[sample]\n",
    "\n",
    "# add percentages to report\n",
    "mcs_output = report_df.loc[mcs].copy()\n",
    "\n",
    "report_df.loc[mcs, \"percentage\"] = (\n",
    "    mcs_output[\"events\"] / mcs_output[\"events\"].sum()\n",
    ") * 100\n",
    "\n",
    "# (https://depts.washington.edu/imreslab/2011%20Lectures/ErrorProp-CountingStat_LRM_04Oct2011.pdf)\n",
    "# add total background number of expected events and error to report\n",
    "report_df.loc[\"Total bkg\", \"events\"] = np.sum(report_df.loc[mcs, \"events\"])\n",
    "report_df.loc[\"Total bkg\", \"error\"] = np.sqrt(\n",
    "    np.sum(report_df.loc[mcs, \"error\"] ** 2)\n",
    ")\n",
    "\n",
    "# add data to bacground ratio and error\n",
    "data = report_df.loc[\"Data\", \"events\"]\n",
    "data_err = report_df.loc[\"Data\", \"error\"]\n",
    "bkg = report_df.loc[\"Total bkg\", \"events\"]\n",
    "bkg_err = report_df.loc[\"Total bkg\", \"error\"]\n",
    "\n",
    "#report_df.loc[\"Data/bkg\", \"events\"] = data / bkg\n",
    "report_df.loc[\"Data/bkg\", \"error\"] = np.sqrt(\n",
    "    (1 / bkg) ** 2 * data_err**2 + (data / bkg**2) ** 2 * bkg_err**2\n",
    ")\n",
    "# sort processes by percentage\n",
    "report_df = report_df.loc[mcs + [\"Total bkg\", \"Data\", \"Data/bkg\"]]\n",
    "report_df = report_df.sort_values(by=\"percentage\", ascending=False)\n",
    "\n",
    "# drop process with no events\n",
    "report_df = report_df.loc[report_df.sum(axis=1) > 0]\n",
    "#report_df.to_csv(\"ele_2b1l/ele_2b1l.csv\")\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc1cd6a9-03e8-4e34-be69-ba70e2ac7c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_outputs = group_outputs()\n",
    "\n",
    "grouped_histograms = {}\n",
    "first_accumulated_histograms = {}\n",
    "for sample in grouped_outputs:\n",
    "    grouped_histograms[sample] = []\n",
    "    for fname in grouped_outputs[sample]:\n",
    "        output = open_output(fname)\n",
    "        grouped_histograms[sample].append(output[\"histograms\"])\n",
    "    first_accumulated_histograms[sample] = processor.accumulate(grouped_histograms[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b53491f-351c-4763-9094-564f0ecbb234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accumulated_histograms = {}\n",
    "for sample in first_accumulated_histograms:\n",
    "    accumulated_histograms[sample] = {}\n",
    "    for kin in first_accumulated_histograms[sample]:\n",
    "        accumulated_histograms[sample][kin] = first_accumulated_histograms[sample][kin][{\"dataset\": sum}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae9d15a4-179c-4966-a36c-561131dbec7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = {}\n",
    "for sample in first_accumulated_metadata:\n",
    "    if sample not in [\"SingleElectron\", \"SingleMuon\"]:\n",
    "        weights[sample] = lumi * xsecs[sample] / first_accumulated_metadata[sample][\"sumw\"]\n",
    "    else:\n",
    "        weights[sample] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccde8649-00f0-4623-9064-bab872bdbc88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaled_histograms = {}\n",
    "for sample in accumulated_histograms:\n",
    "    scaled_histograms[sample] = {}\n",
    "    for kin in accumulated_histograms[sample]:\n",
    "        histogram = copy.deepcopy(accumulated_histograms[sample][kin])\n",
    "        scaled_histograms[sample][kin] = histogram * weights[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da9b3130-3fd8-4547-9d81-f24e4471db78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def group_histograms(scaled_histograms: dict) -> dict:\n",
    "    \"\"\"group scaled histograms by process\"\"\"\n",
    "    hists = {\n",
    "        \"DYJetsToLL\": [],\n",
    "        \"WJetsToLNu\": [],\n",
    "        \"VV\": [],\n",
    "        \"tt\": [],\n",
    "        \"SingleTop\": [],\n",
    "        \"Data\": [],\n",
    "    }\n",
    "    for sample in scaled_histograms:\n",
    "        if \"DYJetsToLL\" in sample:\n",
    "            hists[\"DYJetsToLL\"].append(scaled_histograms[sample])\n",
    "        elif \"WJetsToLNu\" in sample:\n",
    "            hists[\"WJetsToLNu\"].append(scaled_histograms[sample])\n",
    "        elif (sample == \"WW\") or (sample == \"WZ\") or (sample == \"ZZ\"):\n",
    "            hists[\"VV\"].append(scaled_histograms[sample])\n",
    "        elif \"TTT\" in sample:\n",
    "            hists[\"tt\"].append(scaled_histograms[sample])\n",
    "        elif \"ST\" in sample:\n",
    "            hists[\"SingleTop\"].append(scaled_histograms[sample])\n",
    "        elif sample in [\"SingleMuon\", \"SingleElectron\", \"SingleTau\"]:\n",
    "            hists[\"Data\"] = scaled_histograms[sample]\n",
    "\n",
    "    \n",
    "    for sample in hists:\n",
    "        if sample == \"Data\": continue\n",
    "        hists[sample] = processor.accumulate(hists[sample])\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fb2111c-3859-4ead-b1c5-779319c27250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_hists = group_histograms(scaled_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63279da9-8eab-4f3b-a619-bc27a4f6da95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "from coffea import processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e7c876b-1885-4949-8a7d-64b50c56f16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_histogram(\n",
    "    histograms: dict,\n",
    "    kin: str,\n",
    "    var: str,\n",
    "    bkg_errors: dict = None,\n",
    "    channel: str = \"2b1l\",\n",
    "    lepton_flavor: str = \"ele\",\n",
    "    output_dir: str = None,\n",
    "    xlimits: tuple = (None, None),\n",
    "    cms_loc: int = 0,\n",
    "    syst=\"nominal\",\n",
    "    yratio_limits=None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    plot mc and data histograms. include data/bkg ratio plot\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    histograms:\n",
    "        dictionary with hist histograms to plot\n",
    "    kin:\n",
    "        key of the n-dimensional hist histogram\n",
    "        {'jet_kin', 'lepton_kin', 'met_kin', 'lepton_met_kin', 'lepton_bjet_kin', 'lepton_met_bjet_kin'}\n",
    "    var:\n",
    "        variable to plot\n",
    "    bkg_errors:\n",
    "        dictionary with mc error by sample. If None, the 'poisson_interval' function is used\n",
    "    channel:\n",
    "        region channel {\"2b1l\", \"1b1e1mu\"}\n",
    "    lepton_flavor:\n",
    "        lepton channel {'mu', 'ele'}\n",
    "    output_dir:\n",
    "        name of the directory to save the figure\n",
    "    xlimits:\n",
    "        limits for the x axis\n",
    "    cms_loc:\n",
    "        location of the CMS text\n",
    "    \"\"\"\n",
    "    # set style and some plotting params\n",
    "    hep.style.use(hep.style.CMS)\n",
    "    plt.rcParams.update(\n",
    "        {\n",
    "            \"font.size\": 14,\n",
    "            \"axes.titlesize\": 14,\n",
    "            \"axes.labelsize\": 15,\n",
    "            \"xtick.labelsize\": 10,\n",
    "            \"ytick.labelsize\": 10,\n",
    "            \"lines.markersize\": 4,\n",
    "            \"legend.fontsize\": 10,\n",
    "        }\n",
    "    )\n",
    "    plt.rcParams[\"axes.prop_cycle\"] = cycler(\n",
    "        color=[\n",
    "            \"tab:olive\",\n",
    "            \"tab:red\",\n",
    "            \"tab:green\",\n",
    "            \"tab:orange\",\n",
    "            \"tab:blue\",\n",
    "            \"tab:purple\",\n",
    "        ]\n",
    "    )\n",
    "    # get mc and data hists. get labels for mc\n",
    "    mc_labels, mc_histos = [], []\n",
    "    for sample, values in histograms.items():\n",
    "        if values is None:\n",
    "            continue\n",
    "        if sample == \"Data\":\n",
    "            data_hist = values[kin][{\"variation\":syst}].project(var)\n",
    "        else:\n",
    "            mc_labels.append(sample_map[sample])\n",
    "            mc_histos.append(values[kin][{\"variation\":syst}].project(var))\n",
    "            \n",
    "    # define figure and axes for histograms (ax) and ratio plot (rax)\n",
    "    fig, (ax, rax) = plt.subplots(\n",
    "        nrows=2,\n",
    "        ncols=1,\n",
    "        figsize=(6, 6),\n",
    "        tight_layout=True,\n",
    "        gridspec_kw={\"height_ratios\": (3, 1)},\n",
    "        sharex=True,\n",
    "    )\n",
    "    # -----------------------\n",
    "    # mc and data histograms\n",
    "    # -----------------------\n",
    "    # plot mc and data histograms\n",
    "    hep.histplot(mc_histos, label=mc_labels, ax=ax, **mc_hist_kwargs)\n",
    "    hep.histplot(data_hist, label=\"Data\", ax=ax, **data_hist_kwargs)\n",
    "\n",
    "    # get histogram's edges and centers\n",
    "    total_mc = processor.accumulate(mc_histos)\n",
    "    edges = total_mc.axes.edges[0]\n",
    "    centers = total_mc.axes.centers[0]\n",
    "\n",
    "    # get mc stat error\n",
    "    bkg_values = total_mc.values()\n",
    "    bkg_variances = total_mc.variances()\n",
    "    if bkg_errors is None:\n",
    "        bkg_error_down, bkg_error_up = poisson_interval(\n",
    "            values=bkg_values, variances=bkg_variances\n",
    "        )\n",
    "    else:\n",
    "        bkg_error = bkg_errors[kin][var]\n",
    "        bkg_error_down = bkg_values - bkg_error\n",
    "        bkg_error_up = bkg_values + bkg_error\n",
    "        \n",
    "    # plot mc uncertaity interval\n",
    "    \"\"\"\n",
    "    ax.stairs(\n",
    "        values=bkg_error_up,\n",
    "        baseline=bkg_error_down,\n",
    "        edges=edges,\n",
    "        label=\"Stat. unc.\",\n",
    "        **errps,\n",
    "    )\n",
    "    \"\"\"\n",
    "    ratio_uncertainty_band = ax.fill_between(\n",
    "        edges[1:],\n",
    "        bkg_error_up,\n",
    "        bkg_error_down,\n",
    "        label=\"Stat. unc.\",\n",
    "        step=\"pre\",\n",
    "        **errps\n",
    "    )\n",
    "    # set axes labels and legend\n",
    "    ncols = 1\n",
    "    # change legend layout for any distribution with 'eta' or 'phi'\n",
    "    if (\"eta\" in var) or (\"phi\" in var):\n",
    "        ncols = 3\n",
    "        ylim = ax.get_ylim()[1]\n",
    "        ax.set_ylim(0, ylim + 0.4 * ylim)\n",
    "        ax.legend(loc=\"upper center\", ncol=ncols)\n",
    "    else:\n",
    "        ax.legend(loc=\"upper right\", ncol=ncols)\n",
    "    ax.set(\n",
    "        xlabel=None,\n",
    "        ylabel=\"Events\",\n",
    "        xlim=xlimits,\n",
    "    )\n",
    "    # set lumi and CMS text\n",
    "    hep.cms.lumitext(\"41.5 fb$^{-1}$ (2017, 13 TeV)\", fontsize=12, ax=ax)\n",
    "    hep.cms.text(\"Preliminary\", loc=cms_loc, ax=ax)\n",
    "\n",
    "    # --------------------\n",
    "    # data/bkg ratio plot\n",
    "    # --------------------\n",
    "    # get data/bkg ratio and uncertaity interval\n",
    "    # get data/bkg ratio\n",
    "    data_values = data_hist.values()\n",
    "    numerator = data_values\n",
    "    denominator = bkg_values\n",
    "    ratio = numerator / denominator\n",
    "    \n",
    "    # plot data to bkg ratio\n",
    "    xerr = edges[1:] - edges[:-1]\n",
    "    rax.errorbar(\n",
    "        x=centers,\n",
    "        y=ratio,\n",
    "        xerr=xerr / 2,\n",
    "        fmt=\"ko\",\n",
    "        markersize=5,\n",
    "    )\n",
    "    \n",
    "    error_down, error_up = ratio_uncertainty(\n",
    "        num=numerator, denom=denominator, uncertainty_type=\"poisson\"\n",
    "    )\n",
    "    ratio_error_up = ratio + error_up\n",
    "    ratio_error_down = ratio - error_down\n",
    "    \n",
    "    # plot data/bkg error line\n",
    "    rax.vlines(centers, ratio_error_down, ratio_error_up, color=\"k\")\n",
    "    \n",
    "    # get bkg/bkg ratio and uncertaity interval\n",
    "    band_error_down, band_error_up = ratio_uncertainty(\n",
    "        num=bkg_values, denom=bkg_values, uncertainty_type=\"poisson\"\n",
    "    )\n",
    "    ratio_uncertainty_band = rax.fill_between(\n",
    "        edges[1:],\n",
    "        1 + band_error_up,\n",
    "        1 - band_error_down,\n",
    "        step=\"pre\",\n",
    "        **errps\n",
    "    )\n",
    "    \n",
    "    # get ratio plot y-limits\n",
    "    if yratio_limits is None:\n",
    "        up_limit = np.nanmax(ratio_error_up)\n",
    "        down_limit = np.nanmin(ratio_error_down)\n",
    "        scale = 1.1\n",
    "        yup = scale * up_limit\n",
    "        ydown = down_limit - scale * (1 - down_limit)\n",
    "\n",
    "        up_distance = up_limit - 1\n",
    "        down_distance = down_limit - 1\n",
    "        if abs(up_distance) > 2 * abs(down_distance):\n",
    "            ydown = 1 - up_distance\n",
    "        if yup < 0:\n",
    "            yup = 1 + scale * max(down_distance, up_distance)  \n",
    "            \n",
    "        up_distance = abs(1 - yup)\n",
    "        down_distance = abs(1 - ydown)\n",
    "        max_distance = max(down_distance, up_distance)\n",
    "        ydown, yup = 1-max_distance, 1+max_distance\n",
    "    else:\n",
    "        ydown, yup = yratio_limits\n",
    "\n",
    "    # set ratio plot labels, limits and facecolor\n",
    "    rax.set(\n",
    "        xlabel=label_map[lepton_flavor][var],\n",
    "        ylabel=\"Data / Bkg\",\n",
    "        xlim=xlimits,\n",
    "        ylim=(ydown, yup),\n",
    "        facecolor=\"white\",\n",
    "    )\n",
    "    # plot horizontal line at y=1\n",
    "    rax.hlines(1, *rax.get_xlim(), color=\"k\", linestyle=\":\")\n",
    "    # set ratio plot y-label size\n",
    "    rax.yaxis.label.set_size(15)\n",
    "    # save figure\n",
    "    fname = f\"{lepton_flavor}_{channel}/{lepton_flavor}_{channel}_{var}\"\n",
    "    #fig.savefig(f\"{fname}.png\")\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "677b0d54-6285-49e4-9595-ebbb466051b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kin \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m variables[kin]:\n\u001b[0;32m---> 12\u001b[0m         \u001b[43mplot_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocessed_hists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2b1l\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlepton_flavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[30], line 68\u001b[0m, in \u001b[0;36mplot_histogram\u001b[0;34m(histograms, kin, var, bkg_errors, channel, lepton_flavor, output_dir, xlimits, cms_loc, syst, yratio_limits)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 68\u001b[0m     data_hist \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkin\u001b[49m\u001b[43m]\u001b[49m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariation\u001b[39m\u001b[38;5;124m\"\u001b[39m:syst}]\u001b[38;5;241m.\u001b[39mproject(var)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     mc_labels\u001b[38;5;241m.\u001b[39mappend(sample_map[sample])\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "variables = {\n",
    "    \"jet_kin\": [\"jet_pt\", \"jet_eta\", \"jet_phi\"],\n",
    "    \"met_kin\": [\"met\", \"met_phi\"],\n",
    "    \"lepton_kin\": [\"lepton_pt\", \"lepton_eta\", \"lepton_phi\"],\n",
    "    \"lepton_bjet_kin\": [\"lepton_bjet_dr\", \"lepton_bjet_mass\"],\n",
    "    \"lepton_met_kin\": [\"lepton_met_mass\", \"lepton_met_delta_phi\"],\n",
    "    \"lepton_met_bjet_kin\": [\"lepton_met_bjet_mass\"]\n",
    "}\n",
    "\n",
    "for kin in variables:\n",
    "    for var in variables[kin]:\n",
    "        plot_histogram(processed_hists, kin, var, channel=\"2b1l\", lepton_flavor=\"mu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c9123-d99a-4d1f-971b-b14fa45ae54f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
